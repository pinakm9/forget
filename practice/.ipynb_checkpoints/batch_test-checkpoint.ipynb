{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521d2e13-9b85-49e2-9eb9-a6769746b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../../fast-DiT\")\n",
    "sys.path.append(\"../modules\")\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "import dit \n",
    "import utility as ut\n",
    "import datapipe as dp\n",
    "import classifier as cl\n",
    "import train as tt\n",
    "import ortho as uno\n",
    "import ascent as ta\n",
    "import surgery as ts\n",
    "import surgery_a as tsa\n",
    "import ortho_s as tos\n",
    "import batch as bt\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "exchange_classes = [208]\n",
    "forget_class = 207\n",
    "imagenet_json_path = \"../data/ImageNet-1k/imagenet_class_index.json\"\n",
    "data_path = \"../data/ImageNet-1k/2012\"\n",
    "model_path = \"../data/ImageNet-1k/DiT-XL-2\"\n",
    "gen_kwargs = {\"cfg_scale\": 10., \"n_samples\": 10}\n",
    "grid_size = 8\n",
    "experiment_folder = '.'\n",
    "num_experiments = 1\n",
    "\n",
    "# set more experiment parameters\n",
    "params = {\n",
    "    \"model_path\": model_path,\n",
    "    \"batch_size\": 1,\n",
    "    \"log_interval\": 1,\n",
    "    \"collect_interval\": \"epoch\",\n",
    "    \"save_steps\": None,\n",
    "    \"exchange_classes\": exchange_classes,\n",
    "    \"forget_class\": forget_class,\n",
    "    \"data_path\": data_path,\n",
    "    \"imagenet_json_path\": imagenet_json_path,\n",
    "    \"freeze_K\": 0,\n",
    "    \"n_samples\": 1,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "gen_kwargs = {\n",
    "    \"cfg_scale\": 10. \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2624488-a797-45d9-8b7f-52b00d912249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params:     675.13M\n",
      "Trainable params: 1.15M  (y: 1.15M, adaLN_last0: 0.00M, final: 0.00M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                        | 0/1 [00:00<?, ?it/s]/Users/pman0581/miniconda3/envs/uno/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epochs:   0%|                                                        | 0/1 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_cfg_steady() got an unexpected keyword argument 'total_duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m train_kwargs[\u001b[33m\"\u001b[39m\u001b[33mfolder\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/dit-batch\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m be = bt.BatchExperiment(tos.train, train_kwargs, num_experiments)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mbe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/forget/practice/utility.py:19\u001b[39m, in \u001b[36mtimer.<locals>.new_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_func\u001b[39m(*args, **kwargs):\n\u001b[32m     18\u001b[39m \tstart = time()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \tval = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \tend = time()\n\u001b[32m     21\u001b[39m \t\u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTime taken by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend-start\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/forget/practice/batch.py:55\u001b[39m, in \u001b[36mBatchExperiment.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     53\u001b[39m train_kwargs = \u001b[38;5;28mself\u001b[39m.train_kwargs.copy()\n\u001b[32m     54\u001b[39m train_kwargs[\u001b[33m'\u001b[39m\u001b[33mfolder\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_folder(i)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/forget/practice/ortho_s.py:100\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model_path, folder, num_steps, batch_size, save_steps, collect_interval, log_interval, uniformity_weight, orthogonality_weight, exchange_classes, forget_class, img_ext, data_path, imagenet_json_path, n_samples, device, diffusion_steps, freeze_K, unfreeze_last, **gen_kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     99\u001b[39m     loss, elapsed_time = process_batch_even(img_retain, label_retain, img_forget, label_forget)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m generated_img = \u001b[43mlog_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melapsed_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43melapsed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m save(step=global_step)\n\u001b[32m    102\u001b[39m collect_samples(generated_img, step=global_step)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/forget/practice/train.py:211\u001b[39m, in \u001b[36mget_logger.<locals>.log_results\u001b[39m\u001b[34m(step, losses, elapsed_time)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlog_results\u001b[39m(step, losses, elapsed_time):\n\u001b[32m    210\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % log_interval == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m         gen_imgs = \u001b[43mdit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_cfg_steady\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforget_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m         logits = identifier(gen_imgs).logits\n\u001b[32m    213\u001b[39m         class_count = cl.count_from_logits(logits, forget_class) / logits.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mTypeError\u001b[39m: generate_cfg_steady() got an unexpected keyword argument 'total_duration'"
     ]
    }
   ],
   "source": [
    "train_kwargs = params | {\"num_steps\": 2, \"uniformity_weight\": 0e3} | gen_kwargs\n",
    "train_kwargs[\"folder\"] = f\"{experiment_folder}/dit-batch\"\n",
    "be = bt.BatchExperiment(tos.train, train_kwargs, num_experiments)\n",
    "be.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34745d32-61e1-4c7e-b7b9-d5b7f2531df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
