{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b24ce6-9713-448f-b27b-49601f1c4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad, Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "D_r = 5\n",
    "D_rh = int(D_r/2)\n",
    "D_rhh = int(D_rh/2)\n",
    "\n",
    "def get_optim(model):\n",
    "    return optim.Adam(model.parameters(), betas = (0.5, 0.999), lr = 0.0002)\n",
    "\n",
    "def interpolate(real_img, fake_img):\n",
    "    N = real_img.shape[0]\n",
    "    theta = torch.tensor(np.random.uniform(size = N), dtype = torch.float).view(N, 1, 1, 1).cuda()\n",
    "    sample = theta * real_img + (1 - theta) * fake_img\n",
    "    return sample\n",
    "\n",
    "def gradient_norm(model, real_img, fake_img):\n",
    "    N = real_img.shape[0]\n",
    "    _input = interpolate(real_img, fake_img)\n",
    "    _input = Variable(_input, requires_grad = True)\n",
    "    score = model(_input)\n",
    "    outputs = torch.zeros(score.shape).cuda()\n",
    "    gradient = grad(outputs = score, \n",
    "                    inputs = _input, \n",
    "                    grad_outputs = outputs,\n",
    "                    create_graph = True,\n",
    "                    retain_graph = True,\n",
    "                    only_inputs = True)[0]\n",
    "    grad_norm = (gradient.view(N, -1).norm(p = 2) - 1)**2\n",
    "    return grad_norm\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim = 100):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.net = nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.latent_dim, D_r, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_r),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(D_r, D_rh, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_rh),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(D_rh, D_rhh, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_rhh),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(D_rhh, 64, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.ConvTranspose2d(64, 1, 4, 2, 1, bias = False),\n",
    "                nn.Sigmoid()\n",
    "                )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = input.unsqueeze(2).unsqueeze(3)\n",
    "        return self.net(output)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                nn.Conv2d(1, 64, 4, 2, 1, bias = False),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(64, D_rhh, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_rhh),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(D_rhh, D_rh, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_rh),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(D_rh, D_r, 4, 2, 1, bias = False),\n",
    "                nn.BatchNorm2d(D_r),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Conv2d(D_r, 1, 2, 1)\n",
    "                )\n",
    "    def forward(self, input):\n",
    "        return self.net(input).view(-1)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size, pad=False):\n",
    "    if pad:\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Pad(padding = 2, padding_mode = 'edge'),\n",
    "                transforms.ToTensor()\n",
    "                ])\n",
    "    else:\n",
    "        transform = transforms.ToTensor()\n",
    "    \n",
    "    dataset = datasets.MNIST(root = '../data', train = True, download = True, \n",
    "                    transform = transform)\n",
    "    dataloader = DataLoader(dataset = dataset, batch_size = batch_size, \n",
    "                            shuffle = True)\n",
    "    return dataloader\n",
    "\n",
    "def makedirs(sample_dir, checkpoint_dir):\n",
    "    if not os.path.exists(sample_dir):\n",
    "        os.makedirs(sample_dir)\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "def get_optim(model, lr=0.002):\n",
    "    return optim.Adam(model.parameters(), betas = [0.5, 0.999], lr = lr)\n",
    "\n",
    "def interpolate(real_img, fake_img, device):\n",
    "    N = real_img.shape[0]\n",
    "    theta = torch.tensor(np.random.uniform(size = N), dtype = torch.float, device=device).view(N, 1, 1, 1)\n",
    "    sample = theta * real_img + (1 - theta) * fake_img\n",
    "    return sample\n",
    "\n",
    "def gradient_norm(model, real_img, fake_img, device):\n",
    "    N = real_img.shape[0]\n",
    "    _input = interpolate(real_img, fake_img, device)\n",
    "    _input = Variable(_input, requires_grad = True)\n",
    "    score = model(_input)\n",
    "    outputs = torch.zeros(score.shape, device=device)\n",
    "    gradient = grad(outputs = score, \n",
    "                    inputs = _input, \n",
    "                    grad_outputs = outputs,\n",
    "                    create_graph = True,\n",
    "                    retain_graph = True,\n",
    "                    only_inputs = True)[0]\n",
    "    grad_norm = (gradient.view(N, -1).norm(p = 2) - 1)**2\n",
    "    return grad_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14009c92-d685-41d7-853c-6b28e62eba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   5%|█▋                               | 5/100 [05:58<1:53:27, 71.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m real_score \u001b[38;5;241m=\u001b[39m D(real_img)\n\u001b[1;32m     41\u001b[0m fake_score \u001b[38;5;241m=\u001b[39m D(fake_img)\n\u001b[0;32m---> 42\u001b[0m grad_penalty \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m (fake_score \u001b[38;5;241m-\u001b[39m real_score \u001b[38;5;241m+\u001b[39m grad_penalty \u001b[38;5;241m*\u001b[39m gp_weight)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     44\u001b[0m d_loss_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss\n",
      "Cell \u001b[0;32mIn[1], line 126\u001b[0m, in \u001b[0;36mgradient_norm\u001b[0;34m(model, real_img, fake_img, device)\u001b[0m\n\u001b[1;32m    124\u001b[0m score \u001b[38;5;241m=\u001b[39m model(_input)\n\u001b[1;32m    125\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(score\u001b[38;5;241m.\u001b[39mshape, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 126\u001b[0m gradient \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m                \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    132\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m (gradient\u001b[38;5;241m.\u001b[39mview(N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnorm(p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_norm\n",
      "File \u001b[0;32m~/miniconda3/envs/metal/lib/python3.11/site-packages/torch/autograd/__init__.py:394\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    390\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    391\u001b[0m         grad_outputs_\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    405\u001b[0m         output\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (output, \u001b[38;5;28minput\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, t_inputs)\n\u001b[1;32m    409\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "latent_dim = 10\n",
    "d_updates = 5\n",
    "gp_weight = 10\n",
    "\n",
    "dataloader = get_dataloader(batch_size, True)\n",
    "step_per_epoch = np.ceil(dataloader.dataset.__len__() / batch_size)\n",
    "sample_dir = '../data/mnist/wgangp/wgsamples'\n",
    "checkpoint_dir = '../data/mnist/wgangp/checkpoints'\n",
    "\n",
    "makedirs(sample_dir, checkpoint_dir)\n",
    "\n",
    "G = Generator(latent_dim = latent_dim).to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "g_optim = get_optim(G)\n",
    "d_optim = get_optim(D)\n",
    "\n",
    "g_log = []\n",
    "d_log = []\n",
    "    \n",
    "fix_z = torch.randn(100, latent_dim).to(device)\n",
    "for epoch_i in tqdm(range(1, epochs + 1), desc=\"Epochs\"):\n",
    "    for step_i, (real_img, _) in enumerate(dataloader):\n",
    "        N = real_img.shape[0]\n",
    "        \n",
    "        real_labels = torch.ones(batch_size).to(device)\n",
    "        fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "        # Train D\n",
    "        d_loss_avg = 0\n",
    "        for _ in range(d_updates):\n",
    "            real_img = real_img.to(device)\n",
    "            z = torch.randn(N, latent_dim).to(device)\n",
    "            fake_img = G(z)\n",
    "\n",
    "            real_score = D(real_img)\n",
    "            fake_score = D(fake_img)\n",
    "            grad_penalty = gradient_norm(D, real_img, fake_img, device)\n",
    "            d_loss = (fake_score - real_score + grad_penalty * gp_weight).mean()\n",
    "            d_loss_avg += d_loss\n",
    "\n",
    "            d_optim.zero_grad()\n",
    "            d_loss.backward()\n",
    "            d_optim.step()\n",
    "        d_loss_avg /= d_updates\n",
    "        d_log.append(d_loss_avg.item())\n",
    "        \n",
    "        # Train G\n",
    "        z = torch.randn(N, latent_dim).to(device)\n",
    "        fake_img = G(z)\n",
    "        \n",
    "        fake_score = D(fake_img).mean()\n",
    "        \n",
    "        g_loss = -fake_score\n",
    "        \n",
    "        g_optim.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "        g_log.append(g_loss.item())\n",
    "\n",
    "    \n",
    "   # Save the final generator and discriminator models\n",
    "torch.save(G.state_dict(), \"generator_final.pth\")\n",
    "torch.save(D.state_dict(), \"discriminator_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061c767f-a6c6-4074-b8f7-dc4ebb5bb291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─ConvTranspose2d: 2-1              800\n",
      "|    └─BatchNorm2d: 2-2                  10\n",
      "|    └─ReLU: 2-3                         --\n",
      "|    └─ConvTranspose2d: 2-4              160\n",
      "|    └─BatchNorm2d: 2-5                  4\n",
      "|    └─ReLU: 2-6                         --\n",
      "|    └─ConvTranspose2d: 2-7              32\n",
      "|    └─BatchNorm2d: 2-8                  2\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─ConvTranspose2d: 2-10             1,024\n",
      "|    └─BatchNorm2d: 2-11                 128\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─ConvTranspose2d: 2-13             1,024\n",
      "|    └─Sigmoid: 2-14                     --\n",
      "=================================================================\n",
      "Total params: 3,184\n",
      "Trainable params: 3,184\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─ConvTranspose2d: 2-1              800\n",
       "|    └─BatchNorm2d: 2-2                  10\n",
       "|    └─ReLU: 2-3                         --\n",
       "|    └─ConvTranspose2d: 2-4              160\n",
       "|    └─BatchNorm2d: 2-5                  4\n",
       "|    └─ReLU: 2-6                         --\n",
       "|    └─ConvTranspose2d: 2-7              32\n",
       "|    └─BatchNorm2d: 2-8                  2\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─ConvTranspose2d: 2-10             1,024\n",
       "|    └─BatchNorm2d: 2-11                 128\n",
       "|    └─ReLU: 2-12                        --\n",
       "|    └─ConvTranspose2d: 2-13             1,024\n",
       "|    └─Sigmoid: 2-14                     --\n",
       "=================================================================\n",
       "Total params: 3,184\n",
       "Trainable params: 3,184\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60ec06-76b8-43a3-983d-313f333394a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
